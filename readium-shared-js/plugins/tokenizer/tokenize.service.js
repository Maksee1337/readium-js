define(['tokenizr'], function(Tokenizr) {    return function () {        let self = this;        let _lexer = new Tokenizr();        _lexer.rule(/[a-zA-Z_][a-zA-Z0-9_]*/, (ctx, match) => {            ctx.accept("id")        })        _lexer.rule(/[+-]?[0-9]+/, (ctx, match) => {            ctx.accept("number", parseInt(match[0]))        })        _lexer.rule(/"((?:\\"|[^\r\n])*)"/, (ctx, match) => {            ctx.accept("string", match[1].replace(/\\"/g, "\""))        })        _lexer.rule(/\/\/[^\r\n]*\r?\n/, (ctx, match) => {            ctx.ignore()        })        _lexer.rule(/[ \t\r\n]+/, (ctx, match) => {            ctx.ignore()        })        _lexer.rule(/./, (ctx, match) => {            ctx.accept("char")        })        _lexer.debug(false);        this.getObjectsFromText = function (text) {            _lexer.input(text);            return _lexer.tokens();        }    }});